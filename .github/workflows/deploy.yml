name: build-and-deploy

on:
  push:
    branches: [ "main" ]
  workflow_dispatch: {}

permissions:
  contents: read
  packages: write

concurrency:
  group: adaspeas-prod
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    outputs:
      image: ghcr.io/${{ github.repository }}:latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Branch policy (only main branch is allowed)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, os, sys, urllib.request
          repo = os.environ.get('GITHUB_REPOSITORY')
          token = os.environ.get('GITHUB_TOKEN')
          if not repo or not token:
            print('ERROR: missing GITHUB_REPOSITORY or GITHUB_TOKEN')
            sys.exit(1)
          url = f'https://api.github.com/repos/{repo}/branches?per_page=100'
          req = urllib.request.Request(url, headers={
            'Authorization': f'Bearer {token}',
            'Accept': 'application/vnd.github+json',
            'User-Agent': 'adaspeas-ci'
          })
          data = json.loads(urllib.request.urlopen(req).read().decode('utf-8'))
          names = sorted([b.get('name','') for b in data if b.get('name')])
          allowed = {'main'}
          extra = [n for n in names if n not in allowed]
          if set(names) != allowed:
            print('ERROR: policy violation: repository must have exactly one branch: main')
            print('Found branches:', ', '.join(names) if names else '(none)')
            if extra:
              print('Extra branches to delete:', ', '.join(extra))
            print('Fix: delete all branches except main (see docs/WORKFLOW_CONTRACT_RU.md §2.2).')
            sys.exit(1)
          print('OK: only main branch exists.')
          PY
      - name: Repo hygiene (.env must not be tracked, except .env.example)
        shell: bash
        run: |
          set -euo pipefail

          echo "Tracked env-like files:"
          git ls-files -- '.env' '.env.*' || true

          # 1) .env.example must be tracked (template file; used by make env)
          if ! git ls-files --error-unmatch '.env.example' >/dev/null 2>&1; then
            echo "::error::.env.example must be tracked (required template)."
            exit 2
          fi

          # 2) No other tracked dotenv files
          tracked_env="$(git ls-files -- '.env' '.env.*' || true)"
          bad="$(printf '%s\n' "$tracked_env" | grep -vE '(^|/)\.env\.example$' || true)"
          if [ -n "$bad" ]; then
            echo "::error::Forbidden tracked dotenv files (only .env.example allowed):"
            printf '%s\n' "$bad"
            exit 2
          fi

          # 3) Ensure no dependabot / PR templates (they create branches)
          forbid="$(git ls-files -- '.github/dependabot.yml' '.github/pull_request_template.md' '.github/PULL_REQUEST_TEMPLATE.md' || true)"
          if [ -n "$forbid" ]; then
            echo "::error::Forbidden files tracked (policy: no Dependabot/PR template because they create branches):"
            printf '%s\n' "$forbid"
            exit 2
          fi

      - name: Docs policy check (timestamps + no doc sprawl)
        shell: bash
        run: |
          set -euo pipefail

          BEFORE="${{ github.event.before }}"
          AFTER="${{ github.sha }}"

          echo "Checking docs policy for changes: $BEFORE..$AFTER"

          changed_files="$(git diff --name-only "$BEFORE" "$AFTER" || true)"
          added_docs="$(git diff --name-status "$BEFORE" "$AFTER" | awk '$1=="A" && $2 ~ /^docs\// {print $2}' || true)"

          # No new docs files unless ADR/CHATLOG
          if [ -n "${added_docs}" ]; then
            bad="$(echo "${added_docs}" | grep -Ev '^(docs/adr/|docs/CHATLOG_RU\.md$)' || true)"
            if [ -n "${bad}" ]; then
              echo "ERROR: New docs files are not allowed (except ADR/CHATLOG)."
              echo "${bad}"
              exit 1
            fi
          fi

          # Living docs must have timestamp + change log table
          living_docs="docs/INDEX_RU.md docs/WORKFLOW_CONTRACT_RU.md docs/PRD_RU.md docs/TECH_SPEC_RU.md docs/OPS_RUNBOOK_RU.md docs/ROADMAP_RU.md docs/DOCS_RATIONALE_RU.md"

          for f in ${living_docs}; do
            if echo "${changed_files}" | grep -qx "${f}"; then
              echo "Validating living doc: ${f}"
              grep -q '^Актуально на: [0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\} [0-9]\{2\}:[0-9]\{2\} MSK' "${f}"
              grep -q '^## История изменений' "${f}"

              # Table must contain at least one data row with MSK
              if ! grep -E '^[|].*MSK.*[|]' "${f}" >/dev/null; then
                echo "ERROR: ${f} must contain at least one history row in the table."
                exit 1
              fi
            fi
          done

          # If code/infra changed, require CHANGELOG.md or docs/CHATLOG_RU.md updated
          impact="$(
            echo "${changed_files}" \
              | grep -E '^(src/|deploy/|Dockerfile$|docker-compose(\.prod)?\.yml$|requirements\.txt$|\.github/workflows/)' \
              || true
          )"
          if [ -n "${impact}" ]; then
            if ! echo "${changed_files}" | grep -qx "CHANGELOG.md" && ! echo "${changed_files}" | grep -qx "docs/CHATLOG_RU.md"; then
              echo "ERROR: Code/infra changed but CHANGELOG.md or docs/CHATLOG_RU.md not updated."
              echo "${impact}"
              exit 1
            fi
          fi

          echo "Docs policy check passed."

      - name: Python sanity (compile + tests if any)
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: "Проверка: не хранить __pycache__/ и .pyc в репозитории"
        run: |
          set -e
          if git ls-files | grep -E '(^|/)(__pycache__/|.*\.pyc$)' >/dev/null; then
            echo "Ошибка: в репозитории есть отслеживаемые __pycache__/ или .pyc. Удалите их из git (git rm -r --cached) и закоммитьте."
            git ls-files | grep -E '(^|/)(__pycache__/|.*\.pyc$)' || true
            exit 1
          fi

      - name: Compile + pytest
        run: |
          python -m compileall -q src
          pytest -q || test $? -eq 5

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build & push
        id: meta
        uses: docker/build-push-action@v6
        with:
          context: .
          file: Dockerfile
          push: true
          cache-from: type=gha
          cache-to: type=gha,mode=max
          tags: |
            ghcr.io/${{ github.repository }}:latest
            ghcr.io/${{ github.repository }}:${{ github.sha }}


  ci-smoke:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure .env exists for Compose
        shell: bash
        run: |
          set -euo pipefail
          if [ ! -f .env ]; then
            if [ -f .env.example ]; then
              cp .env.example .env
            else
              : > .env
            fi
          fi
          # В CI-smoke принудительно включаем режим, при котором бот не падает на фейковом токене
          if grep -q "^CI_SMOKE=" .env; then
            sed -i "s/^CI_SMOKE=.*/CI_SMOKE=1/" .env
          else
            echo "CI_SMOKE=1" >> .env
          fi
      - name: Dockerfile lint (hadolint)
        uses: hadolint/hadolint-action@v3.1.0
        with:
          dockerfile: Dockerfile
          no-fail: true

      - name: Trivy report (fs, SARIF)
        uses: aquasecurity/trivy-action@0.33.1
        with:
          scan-type: fs
          scan-ref: .
          format: sarif
          output: trivy-results.sarif
          exit-code: 0
          ignore-unfixed: true

      - name: Upload Trivy SARIF
        if: always() && hashFiles('trivy-results.sarif') != ''
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: trivy-results.sarif

      - name: Trivy gate (fs, fail on HIGH/CRITICAL)
        uses: aquasecurity/trivy-action@0.33.1
        with:
          scan-type: fs
          scan-ref: .
          format: table
          severity: HIGH,CRITICAL
          ignore-unfixed: true
          exit-code: 1
          skip-setup-trivy: true

      - name: Compose config validate (dev)
        run: docker compose -f docker-compose.yml config

      - name: Start stack (dev)
        run: docker compose -f docker-compose.yml up -d --build --remove-orphans

      - name: Wait for /health (bot 8080, worker 8081)
        run: |
          set -eu
          for i in $(seq 1 60); do
            if curl -fsS "http://localhost:8080/health" >/dev/null && curl -fsS "http://localhost:8081/health" >/dev/null; then
              echo "healthy"
              exit 0
            fi
            sleep 2
          done
          echo "healthcheck timeout"
          docker compose -f docker-compose.yml ps
          docker compose -f docker-compose.yml logs --no-color
          exit 1

      - name: Teardown
        if: always()
        run: docker compose -f docker-compose.yml down -v || true

  deploy:
    needs: [build, ci-smoke]
    runs-on: ubuntu-latest
    steps:
      - name: Deploy over SSH
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.VPS_HOST }}
          username: ${{ secrets.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          port: ${{ secrets.VPS_PORT }}
          script_stop: true
          envs: GHCR_USER,GHCR_PAT,APP_DIR,IMAGE
          script: |
            set -euo pipefail
            export APP_DIR="${APP_DIR:-/opt/adaspeas}"
            export IMAGE="${IMAGE:-${{ needs.build.outputs.image }}}"

            dump_state() {
              echo "\n=== docker compose ps (prod) ==="
              docker compose -f docker-compose.prod.yml ps || true
              echo "\n=== docker compose logs (tail, prod) ==="
              docker compose -f docker-compose.prod.yml logs --no-color --tail 200 bot worker caddy || true
            }

            # If something goes wrong, show container state/logs to avoid "bot is unhealthy" guesswork.
            trap 'echo "\nDEPLOY FAILED"; dump_state' ERR
            if [ ! -d "$APP_DIR" ]; then
              echo "APP_DIR $APP_DIR does not exist. Run deploy/bootstrap_vps.sh on the server first."
              exit 2
            fi
            cd "$APP_DIR"

            # keep VPS repo in sync with GitHub (infra files, docs, compose, caddy)
            git fetch origin
            git reset --hard origin/main
            git clean -fd

            # validate required env vars (fail fast before pulling/up)
            if [ ! -f .env ]; then
              echo "Missing .env in $APP_DIR"
              exit 3
            fi

            get_env() {
              grep -E "^${1}=" .env | tail -n1 | cut -d= -f2- || true
            }

            must() {
              k="$1"
              v="$(get_env "$k")"
              if [ -z "$v" ]; then
                echo "Missing or empty env var: $k"
                exit 3
              fi
            }

            # always required
            must BOT_TOKEN
            must SQLITE_PATH
            must REDIS_URL
            must ACME_EMAIL
            must METRICS_USER
            must METRICS_PASS
            must IMAGE

            storage_mode="$(get_env STORAGE_MODE)"
            if [ -z "$storage_mode" ]; then storage_mode="yandex"; fi

            if [ "$storage_mode" = "yandex" ]; then
              must YANDEX_OAUTH_TOKEN
              must YANDEX_BASE_PATH
            elif [ "$storage_mode" = "local" ]; then
              must LOCAL_STORAGE_ROOT
            else
              echo "Unknown STORAGE_MODE=$storage_mode (expected: yandex|local)"
              exit 3
            fi

            if [ "$(get_env USE_LOCAL_BOT_API)" = "1" ]; then
              must TELEGRAM_API_ID
              must TELEGRAM_API_HASH
              must LOCAL_BOT_API_BASE
              if [ -z "${COMPOSE_PROFILES:-}" ]; then
                export COMPOSE_PROFILES="localbotapi"
              else
                export COMPOSE_PROFILES="${COMPOSE_PROFILES},localbotapi"
              fi
            fi

            if [ -n "${GHCR_PAT:-}" ]; then
              echo "$GHCR_PAT" | docker login ghcr.io -u "${GHCR_USER:-${{ github.actor }}}" --password-stdin
            fi

            docker compose -f docker-compose.prod.yml pull
            docker compose -f docker-compose.prod.yml up -d --remove-orphans

            wait_healthy() {
              svc="$1"
              id="$(docker compose -f docker-compose.prod.yml ps -q "$svc" || true)"
              if [ -z "$id" ]; then
                echo "Service $svc not found"
                exit 4
              fi
              for i in $(seq 1 60); do
                st="$(docker inspect --format '{{if .State.Health}}{{.State.Health.Status}}{{else}}none{{end}}' "$id" 2>/dev/null || true)"
                if [ "$st" = "healthy" ]; then
                  echo "$svc: healthy"
                  return 0
                fi
                if [ "$st" = "unhealthy" ]; then
                  echo "$svc: unhealthy"
                  dump_state
                  exit 5
                fi
                sleep 2
              done
              echo "$svc: health timeout"
              dump_state
              exit 5
            }

            wait_healthy bot
            wait_healthy worker

            docker compose -f docker-compose.prod.yml restart caddy
            docker image prune -f
        env:
          GHCR_USER: ${{ secrets.GHCR_USER }}
          GHCR_PAT: ${{ secrets.GHCR_PAT }}
          APP_DIR: ${{ secrets.APP_DIR }}
          VPS_PORT: ${{ secrets.VPS_PORT }}
          IMAGE: ghcr.io/${{ github.repository }}:latest
